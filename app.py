import streamlit as st
import fitz
import traceback
import time
import re
import json
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from abc import ABC, abstractmethod
from io import BytesIO

# éœ€è¦å®‰è£…çš„ä¾èµ–åŒ…
# pip install streamlit PyMuPDF python-pptx openai anthropic google-generativeai

try:
    from pptx import Presentation
    from pptx.util import Inches, Pt
    from pptx.enum.text import PP_ALIGN
    from pptx.dml.color import RGBColor
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# --- é…ç½®åŒºåŸŸ ---
@dataclass
class APIConfig:
    """APIé…ç½®ç±»"""
    openai_key: str = ""
    anthropic_key: str = ""
    gemini_key: str = ""

# é»˜è®¤é…ç½® - ç”¨æˆ·å¯ä»¥åœ¨è¿™é‡Œé¢„è®¾API Keys
DEFAULT_CONFIG = APIConfig(
    gemini_key="",      # åœ¨è¿™é‡Œå¡«å…¥ä½ çš„Gemini API Key
    openai_key="",      # åœ¨è¿™é‡Œå¡«å…¥ä½ çš„OpenAI API Key
    anthropic_key=""    # åœ¨è¿™é‡Œå¡«å…¥ä½ çš„Claude API Key
)

# --- AIå‚å•†æŠ½è±¡æ¥å£ ---
class AIProvider(ABC):
    """AIå‚å•†ç»Ÿä¸€æ¥å£"""
    
    @abstractmethod
    def call_api(self, prompt: str, model: str, api_key: str, stream_callback=None) -> Optional[str]:
        """è°ƒç”¨AI API"""
        pass
    
    @abstractmethod
    def get_models(self) -> List[str]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        pass
    
    @abstractmethod
    def validate_key(self, api_key: str) -> bool:
        """éªŒè¯API Key"""
        pass

class GeminiProvider(AIProvider):
    """Google Gemini Provider"""
    
    def get_models(self) -> List[str]:
        return ['gemini-2.5-flash', 'gemini-2.0-flash', 'gemini-1.5-flash']
    
    def validate_key(self, api_key: str) -> bool:
        if not GEMINI_AVAILABLE or not api_key:
            return False
        try:
            genai.configure(api_key=api_key)
            list(genai.list_models())
            return True
        except:
            return False
    
    def call_api(self, prompt: str, model: str, api_key: str, stream_callback=None) -> Optional[str]:
        try:
            genai.configure(api_key=api_key)
            ai_model = genai.GenerativeModel(model)
            
            if stream_callback:
                response_stream = ai_model.generate_content(prompt, stream=True)
                collected_chunks = []
                for chunk in response_stream:
                    if hasattr(chunk, 'text'):
                        text_part = chunk.text
                        collected_chunks.append(text_part)
                        stream_callback(text_part)
                return "".join(collected_chunks)
            else:
                response = ai_model.generate_content(prompt)
                return response.text if hasattr(response, 'text') else None
        except Exception as e:
            st.error(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            return None

class OpenAIProvider(AIProvider):
    """OpenAI Provider"""
    
    def get_models(self) -> List[str]:
        return ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-3.5-turbo']
    
    def validate_key(self, api_key: str) -> bool:
        if not OPENAI_AVAILABLE or not api_key:
            return False
        try:
            client = openai.OpenAI(api_key=api_key)
            client.models.list()
            return True
        except:
            return False
    
    def call_api(self, prompt: str, model: str, api_key: str, stream_callback=None) -> Optional[str]:
        try:
            client = openai.OpenAI(api_key=api_key)
            
            if stream_callback:
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    stream=True
                )
                collected_chunks = []
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        text_part = chunk.choices[0].delta.content
                        collected_chunks.append(text_part)
                        stream_callback(text_part)
                return "".join(collected_chunks)
            else:
                response = client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
        except Exception as e:
            st.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return None

class AnthropicProvider(AIProvider):
    """Anthropic Claude Provider"""
    
    def get_models(self) -> List[str]:
        return ['claude-3-5-sonnet-20241022', 'claude-3-5-haiku-20241022', 'claude-3-opus-20240229']
    
    def validate_key(self, api_key: str) -> bool:
        if not ANTHROPIC_AVAILABLE or not api_key:
            return False
        try:
            client = anthropic.Anthropic(api_key=api_key)
            # ç®€å•éªŒè¯ï¼Œå‘é€ä¸€ä¸ªå¾ˆçŸ­çš„æ¶ˆæ¯
            client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=10,
                messages=[{"role": "user", "content": "Hi"}]
            )
            return True
        except:
            return False
    
    def call_api(self, prompt: str, model: str, api_key: str, stream_callback=None) -> Optional[str]:
        try:
            client = anthropic.Anthropic(api_key=api_key)
            
            if stream_callback:
                response = client.messages.create(
                    model=model,
                    max_tokens=4000,
                    messages=[{"role": "user", "content": prompt}],
                    stream=True
                )
                collected_chunks = []
                for chunk in response:
                    if chunk.type == "content_block_delta":
                        text_part = chunk.delta.text
                        collected_chunks.append(text_part)
                        stream_callback(text_part)
                return "".join(collected_chunks)
            else:
                response = client.messages.create(
                    model=model,
                    max_tokens=4000,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
        except Exception as e:
            st.error(f"Claude APIè°ƒç”¨å¤±è´¥: {e}")
            return None

class UniversalProvider(AIProvider):
    """é€šç”¨HTTP API Provider (é€‚ç”¨äºKimi, Doubao, é€šä¹‰åƒé—®ç­‰)"""
    
    def __init__(self, provider_name: str, base_url: str, models: List[str]):
        self.provider_name = provider_name
        self.base_url = base_url
        self.models = models
    
    def get_models(self) -> List[str]:
        return self.models
    
    def validate_key(self, api_key: str) -> bool:
        if not api_key:
            return False
        try:
            # ç®€å•çš„éªŒè¯è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            # å¤§å¤šæ•°APIéƒ½æœ‰modelsç«¯ç‚¹
            response = requests.get(f"{self.base_url}/models", headers=headers, timeout=10)
            return response.status_code == 200
        except:
            return False
    
    def call_api(self, prompt: str, model: str, api_key: str, stream_callback=None) -> Optional[str]:
        try:
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "stream": bool(stream_callback)
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=data,
                stream=bool(stream_callback),
                timeout=300
            )
            
            if stream_callback:
                collected_chunks = []
                for line in response.iter_lines():
                    if line:
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            try:
                                json_data = json.loads(line[6:])
                                if 'choices' in json_data and json_data['choices']:
                                    delta = json_data['choices'][0].get('delta', {})
                                    if 'content' in delta:
                                        text_part = delta['content']
                                        collected_chunks.append(text_part)
                                        stream_callback(text_part)
                            except:
                                continue
                return "".join(collected_chunks)
            else:
                result = response.json()
                return result['choices'][0]['message']['content']
                
        except Exception as e:
            st.error(f"{self.provider_name} APIè°ƒç”¨å¤±è´¥: {e}")
            return None

# åˆå§‹åŒ–æ‰€æœ‰AIå‚å•†
PROVIDERS = {
    "Gemini": GeminiProvider(),
    "OpenAI": OpenAIProvider(),
    "Claude": AnthropicProvider(),
    "Kimi": UniversalProvider("Kimi", "https://api.moonshot.cn/v1", ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"]),
    "Doubao": UniversalProvider("Doubao", "https://ark.cn-beijing.volces.com/api/v3", ["ep-20241022-******"]),  # éœ€è¦ç”¨æˆ·å¡«å…¥å®é™…endpoint
    "é€šä¹‰åƒé—®": UniversalProvider("é€šä¹‰åƒé—®", "https://dashscope.aliyuncs.com/compatible-mode/v1", ["qwen-turbo", "qwen-plus", "qwen-max"]),
    "æ™ºè°±AI": UniversalProvider("æ™ºè°±AI", "https://open.bigmodel.cn/api/paas/v4", ["glm-4", "glm-4-plus", "glm-4-0520"]),
    "DeepSeek": UniversalProvider("DeepSeek", "https://api.deepseek.com/v1", ["deepseek-chat", "deepseek-coder"]),
    "ç¡…åŸºæµåŠ¨": UniversalProvider("ç¡…åŸºæµåŠ¨", "https://api.siliconflow.cn/v1", ["Qwen/Qwen2.5-72B-Instruct", "deepseek-ai/DeepSeek-V2.5"])
}

# --- æç¤ºè¯æ¨¡æ¿ (ä¿æŒä¸å˜) ---
OUTLINE_GENERATION_PROMPT_TEMPLATE = """
è§’è‰² (Role):
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„å­¦æœ¯æ±‡æŠ¥è®¾è®¡å¸ˆå’Œå†…å®¹ç­–ç•¥å¸ˆï¼ŒåŒæ—¶å…·å¤‡å‡ºè‰²çš„**"æ— å›¾åŒ–è®¾è®¡" (Graphic-less Design)** æ€ç»´ã€‚ä½ ç²¾é€šå°†å¤æ‚çš„å­¦æœ¯è®ºæ–‡è½¬åŒ–ä¸ºç»“æ„åŒ–ã€è§†è§‰åŒ–çš„æ¼”ç¤ºæ–‡ç¨¿ï¼ˆPPTï¼‰ï¼Œå¹¶ä¸”æ“…é•¿ä½¿ç”¨CSSæ ·å¼ã€å¸ƒå±€å’Œæ–‡æœ¬ç¬¦å·æ¥åˆ›é€ æ¸…æ™°ã€ä¼˜é›…çš„è§†è§‰æ•ˆæœï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘å¯¹å¤–éƒ¨å›¾ç‰‡æˆ–å¤æ‚SVGçš„ä¾èµ–ã€‚

æ ¸å¿ƒä»»åŠ¡ (Core Task):
åˆ†æç”¨æˆ·ä¸Šä¼ çš„å­¦æœ¯æ–‡æ¡£ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„ã€é€é¡µçš„æ¼”ç¤ºæ–‡ç¨¿å¤§çº²ã€‚è¿™ä¸ªå¤§çº²éœ€è¦ç›´æ¥æ˜ å°„åˆ°ä¸€ä¸ªé¢„è®¾çš„HTMLæ±‡æŠ¥æ¨¡æ¿ä¸­ã€‚ä½ éœ€è¦å†³å®šå°†æ–‡æ¡£å†…å®¹åˆ’åˆ†æˆå¤šå°‘é¡µPPTæ˜¯åˆé€‚çš„ï¼ˆé€šå¸¸åœ¨10-15é¡µä¹‹é—´ï¼‰ï¼Œå¹¶ä¸ºæ¯ä¸€é¡µè®¾è®¡å†…å®¹å’Œå¯é€šè¿‡ç®€å•ä»£ç å®ç°çš„è§†è§‰å…ƒç´ ã€‚

å…³é”®åŸåˆ™ (Guiding Principles):
ä¸€é¡µä¸€æ ¸å¿ƒ: æ¯å¼ å¹»ç¯ç‰‡åªä¼ è¾¾ä¸€ä¸ªæ ¸å¿ƒè§‚ç‚¹ã€‚
åŒ–ç¹ä¸ºç®€: å°†é•¿å¥è½¬åŒ–ä¸ºç²¾ç‚¼çš„è¦ç‚¹ã€çŸ­è¯­æˆ–å…³é”®è¯ã€‚
é€»è¾‘æµç•…: éµå¾ªæ ‡å‡†çš„å­¦æœ¯æ±‡æŠ¥é€»è¾‘ï¼ˆå¼•è¨€ -> æ–¹æ³• -> ç»“æœ -> ç»“è®ºï¼‰ã€‚
æå–å…³é”®: ç›´æ¥ä»åŸæ–‡ä¸­æå–å…³é”®æœ¯è¯­ã€æ•°æ®ã€ç»“æœå’Œå¼•ç”¨ã€‚
CSSä¼˜å…ˆï¼Œæ— å›¾ä¸ºä¸» (CSS First, Image-Free): è¿™æ˜¯æœ€é‡è¦çš„åŸåˆ™ã€‚ ä½ å¿…é¡»ä¼˜å…ˆè€ƒè™‘é‚£äº›å¯ä»¥é€šè¿‡çº¯CSSã€Emojiæˆ–åŸºæœ¬HTMLç»“æ„å®ç°çš„è§†è§‰å…ƒç´ ã€‚ç»å¯¹ç¦æ­¢å»ºè®®ä½¿ç”¨å¤–éƒ¨å›¾ç‰‡é“¾æ¥ã€‚ ä»…åœ¨æå…¶å¿…è¦ä¸”å½¢çŠ¶æå…¶ç®€å•ï¼ˆå¦‚åœ†å½¢ã€ç®­å¤´ï¼‰çš„æƒ…å†µä¸‹ï¼Œæ‰å»ºè®®ä½¿ç”¨SVGè·¯å¾„ã€‚

è¾“å‡ºæ ¼å¼ (Required Output Format):
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼ä¸ºæ¯ä¸€é¡µå¹»ç¯ç‰‡ç”Ÿæˆå†…å®¹ã€‚ä½¿ç”¨ --- åˆ†éš”æ¯ä¸€é¡µã€‚

---
**Slide:** [å¹»ç¯ç‰‡é¡µç ï¼Œä»1å¼€å§‹]
**Title:** [å¹»ç¯ç‰‡æ ‡é¢˜]
**Purpose:** [å¹»ç¯ç‰‡ç›®çš„/ç±»å‹ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©: Title, Overview, Background, Methodology, Data, Results, Analysis, Discussion, Conclusion, Future_Work, Acknowledgements]
**Content:**
- [è¦ç‚¹1ï¼šç®€æ´çš„çŸ­å¥æˆ–çŸ­è¯­]
- [è¦ç‚¹2ï¼š**åŠ ç²—**å…³é”®æœ¯è¯­]
- [è¦ç‚¹3ï¼šç›´æ¥å¼•ç”¨åŸæ–‡çš„ä¸€å¥æ ¸å¿ƒè§‚ç‚¹]
**Visual:**
  - **Type:** [ä»ä»¥ä¸‹è§†è§‰ç±»å‹ä¸­é€‰æ‹©: `Symbol`, `Process`, `Chart`, `Table`, `Quote`, `Comparison`, `List`, `Text_Only`]
  - **Data:** [æ ¹æ®é€‰æ‹©çš„Typeæä¾›ç»“æ„åŒ–æ•°æ®ã€‚è¿™æ˜¯æœ€å…³é”®çš„éƒ¨åˆ†ï¼Œæ ¼å¼è§ä¸‹æ–¹è¯´æ˜ã€‚]
---

Visual.Data æ ¼å¼è¯´æ˜ (å·²ä¼˜åŒ–):
Type: Symbol
Data:
symbol: [ä¸€ä¸ªUnicode Emojiè¡¨æƒ…ç¬¦å·]
text: [ç¬¦å·æ—è¾¹çš„ç®€çŸ­è¯´æ˜æ–‡å­—]
color_hint: [ä¸€ä¸ªCSSé¢œè‰²æç¤º]

Type: Process
Data:
steps: [ä¸€ä¸ªJSONæ•°ç»„]
style: [numbered-list, chevron-arrow]

Type: Chart
Data:
chart_type: [bar, line, pie]
title: [å›¾è¡¨æ ‡é¢˜]
data_summary: [å¯¹å›¾è¡¨æ ¸å¿ƒæ•°æ®çš„æ–‡å­—æè¿°]

Type: Table
Data:
caption: [è¡¨æ ¼æ ‡é¢˜]
headers: [ä¸€ä¸ªJSONæ•°ç»„]
rows: [ä¸€ä¸ªåŒ…å«å¤šè¡Œæ•°æ®çš„JSONæ•°ç»„]

Type: Quote
Data:
text: [å¼•ç”¨çš„æ ¸å¿ƒæ–‡æœ¬]
source: [å¼•ç”¨æ¥æº]

Type: Comparison
Data:
item1_title: [å¯¹æ¯”é¡¹1çš„æ ‡é¢˜]
item1_points: [ä¸€ä¸ªJSONæ•°ç»„]
item2_title: [å¯¹æ¯”é¡¹2çš„æ ‡é¢˜]
item2_points: [ä¸€ä¸ªJSONæ•°ç»„]

Type: List æˆ– Type: Text_Only
Data: null

æŒ‡ä»¤ (Instruction):
ç°åœ¨ï¼Œè¯·åˆ†æç”¨æˆ·ä¸Šä¼ çš„è¿™ä»½å­¦æœ¯æ–‡æ¡£ã€‚ä¸¥æ ¼éµå¾ªä»¥ä¸Šæ‰€æœ‰è§„åˆ™å’Œ**"æ— å›¾åŒ–è®¾è®¡"åŸåˆ™ï¼Œä¸ºå…¶ç”Ÿæˆä¸€ä»½å®Œæ•´çš„ã€é€»è¾‘æ¸…æ™°çš„ã€å¼ºè°ƒä½¿ç”¨ç®€å•ç¬¦å·å’ŒCSS**è¿›è¡Œè§†è§‰å‘ˆç°çš„å­¦æœ¯æ¼”ç¤ºæ–‡ç¨¿å¤§çº²ã€‚è¯·å¼€å§‹ã€‚
"""

CODE_GENERATION_PROMPT_TEMPLATE = """
è§’è‰² (Role):
ä½ æ˜¯ä¸€ä½ç²¾é€šHTMLã€CSSå’ŒJavaScriptçš„å‰ç«¯å¼€å‘ä¸“å®¶ï¼Œæ‹¥æœ‰åƒç´ çº§çš„ä»£ç ä¿çœŸèƒ½åŠ›ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯å°†ç»“æ„åŒ–çš„Markdownå¤§çº²ï¼Œæ— æŸåœ°ã€ç²¾ç¡®åœ°ä¸ä¸€ä¸ªé¢„å®šä¹‰çš„HTMLæ¨¡æ¿ç›¸ç»“åˆï¼ŒåŠ¨æ€ç”Ÿæˆæœ€ç»ˆçš„ã€å¯ç›´æ¥è¿è¡Œçš„ã€é«˜åº¦ä¸“ä¸šçš„HTMLæ–‡ä»¶ã€‚ä½ å¯¹ç»†èŠ‚æœ‰æé«˜çš„è¦æ±‚ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å›¾åƒèµ„æºå’Œæ•°æ®å¯è§†åŒ–å ä½æ–¹é¢ã€‚

æ ¸å¿ƒä»»åŠ¡ (Core Task):
ä½ å°†æ”¶åˆ°ä¸¤ä»½è¾“å…¥ï¼š
1. **PPTå¤§çº² (PPT Outline):** ä¸€ä»½ç”±AIé¢„å…ˆç”Ÿæˆçš„ã€ç»“æ„åŒ–çš„Markdownæ–‡ä»¶ã€‚
2. **HTMLæ¨¡æ¿ (HTML Template):** ä¸€ä¸ªå®Œæ•´çš„HTMLæ–‡ä»¶ï¼ŒåŒ…å«äº†æ‰€æœ‰å¿…é¡»çš„æ ·å¼ã€è„šæœ¬å’Œå…³é”®èµ„æºï¼ˆå¦‚Base64ç¼–ç çš„æ ¡å¾½ï¼‰ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. **è§£æå¤§çº²:** é€é¡µè§£æPPTå¤§çº²ä¸­çš„æ‰€æœ‰å­—æ®µï¼ˆSlideã€Titleã€Purposeã€Contentã€Visualç­‰ï¼‰ã€‚
2. **åŠ¨æ€ç”Ÿæˆå¹»ç¯ç‰‡:** æ ¹æ®è§£æå‡ºçš„æ•°æ®ï¼Œä¸ºæ¯ä¸€é¡µå¹»ç¯ç‰‡ç”Ÿæˆå¯¹åº”çš„HTML `<section>` å…ƒç´ ï¼Œå¹¶åº”ç”¨æ­£ç¡®çš„CSSç±»ã€‚
3. **æ™ºèƒ½æ¸²æŸ“è§†è§‰å…ƒç´ :**
   - **å¯¹äºå›¾è¡¨ (Visual.Type: Chart):** ç»ä¸åœ¨é¡µé¢ä¸Šæ˜¾ç¤º"å ä½ç¬¦"å­—æ ·ã€‚ä½ åº”è¯¥åœ¨å›¾è¡¨åŒºåŸŸå†…ï¼Œä½¿ç”¨ä¼˜é›…çš„æ’ç‰ˆï¼Œå°†å¤§çº²ä¸­æä¾›çš„ `Visual.Data.data_summary` (æ•°æ®æ‘˜è¦æ–‡å­—) ç›´æ¥å±•ç¤ºå‡ºæ¥ã€‚è¿™ä¸ºæ¼”è®²è€…æä¾›äº†ä¸€ä¸ªè®¨è®ºæ•°æ®çš„èµ·ç‚¹ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç©ºæ´çš„å ä½ç¬¦ã€‚
   - **å¯¹äºç¬¦å· (Visual.Type: Symbol):** å°†å¤§çº²ä¸­æŒ‡å®šçš„Emojiç¬¦å· (`Visual.Data.symbol`) ç›´æ¥ä½œä¸ºæ–‡æœ¬æ’å…¥åˆ°HTMLä¸­ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°ä½¿ç”¨ `Visual.Data.color_hint` ä½œä¸ºå†…è”æ ·å¼çš„é¢œè‰²ã€‚
   - **å¯¹äºå…¶ä»–ç±»å‹:** æ ¹æ®Visual.Typeå’ŒVisual.Dataæ™ºèƒ½ç”Ÿæˆç›¸åº”çš„HTMLç»“æ„ã€‚
4. **ã€æœ€é«˜ä¼˜å…ˆçº§ - é“å¾‹ã€‘ä¿æŠ¤å…³é”®èµ„æº:** åœ¨æ•´åˆä»£ç æ—¶ï¼Œå¿…é¡»å®Œæ•´ã€æ— è¯¯åœ°ä¿ç•™HTMLæ¨¡æ¿ä¸­æ‰€æœ‰çš„ï¼š
   - æ•´ä¸ª`<head>`æ ‡ç­¾ï¼ŒåŒ…å«æ‰€æœ‰çš„`<link>`å’Œ`<style>`
   - æ•´ä¸ª`<script>`æ ‡ç­¾åŠå…¶å†…éƒ¨æ‰€æœ‰çš„JavaScriptä»£ç 
   - æ‰€æœ‰å¯¼èˆªæ§ä»¶ã€é¡µç æŒ‡ç¤ºå™¨ç­‰éå¹»ç¯ç‰‡å†…å®¹
   - **ç‰¹åˆ«é‡è¦:** æ‰€æœ‰`<img>`æ ‡ç­¾åŠå…¶`src`å±æ€§ï¼Œå°¤å…¶æ˜¯é‚£äº›åŒ…å« `data:image/svg+xml;base64,...` çš„é•¿å­—ç¬¦ä¸²ã€‚ç»ä¸å…è®¸å¯¹è¿™äº›èµ„æºé“¾æ¥è¿›è¡Œä»»ä½•å½¢å¼çš„ä¿®æ”¹ã€ç¼©çŸ­æˆ–åˆ é™¤ã€‚
5. **æ— ç¼æ•´åˆ:** ç¡®ä¿åŠ¨æ€ç”Ÿæˆçš„å¹»ç¯ç‰‡æ•°é‡ä¸åº•éƒ¨çš„ç¼©ç•¥å›¾å¯¼èˆªå’Œæ¼”è®²è€…å¤‡æ³¨çš„æ¡ç›®æ•°é‡å®Œå…¨ä¸€è‡´ã€‚
6. **ä»£ç æ•´æ´:** ç”Ÿæˆçš„HTMLä»£ç å¿…é¡»æœ‰è‰¯å¥½çš„ç¼©è¿›å’Œå¯è¯»æ€§ã€‚

**ã€ç»å¯¹ç¦æ­¢ - è¾“å‡ºè¦æ±‚ã€‘:**
- ä½ çš„æœ€ç»ˆè¾“å‡º **ç»å¯¹ä¸èƒ½** åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—æˆ–Markdownä»£ç å—æ ‡è®°
- ä¸è¦ä½¿ç”¨```htmlæˆ–```ç­‰Markdownä»£ç å—æ ‡è®°
- ä¸è¦åœ¨HTMLå‰åæ·»åŠ ä»»ä½•è§£é‡Šæ€§å†…å®¹
- è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªçº¯ç²¹çš„HTMLæ–‡æœ¬ï¼Œç›´æ¥ä»¥ `<!DOCTYPE html>` å¼€å¤´ï¼Œå¹¶ä»¥ `</html>` ç»“å°¾

æŒ‡ä»¤ (Instruction):
ä»¥ä¸‹æ˜¯ç”¨æˆ·æä¾›çš„ **PPTå¤§çº² (PPT Outline)** å’Œ **HTMLæ¨¡æ¿ (HTML Template)**ã€‚è¯·ä½ ç«‹å³å¼€å§‹å·¥ä½œï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸Šæ‰€æœ‰è§„åˆ™ï¼Œç‰¹åˆ«æ˜¯ä¿æŠ¤æ ¡å¾½ç­‰å…³é”®èµ„æºå’Œä¼˜é›…å¤„ç†å›¾è¡¨å ä½çš„æŒ‡ä»¤ï¼Œå°†å¤§çº²å†…å®¹ä¸æ¨¡æ¿ä»£ç ç»“åˆï¼Œç”Ÿæˆæœ€ç»ˆçš„ã€å®Œæ•´çš„ã€ä¸“ä¸šçº§çš„HTMLæ–‡ä»¶ã€‚ä¸è¦æä¾›ä»»ä½•è§£é‡Šæˆ–è¯„è®ºï¼Œç›´æ¥è¾“å‡ºå®Œæ•´çš„HTMLä»£ç ã€‚
"""

# --- PPTç”Ÿæˆå™¨ ---
class PPTGenerator:
    """PPTç”Ÿæˆå™¨ç±»"""
    
    def __init__(self):
        self.presentation = None
    
    def create_presentation(self, outline_data: str, template_path: str = None) -> BytesIO:
        """æ ¹æ®å¤§çº²åˆ›å»ºPPT"""
        if not PPTX_AVAILABLE:
            raise ImportError("python-pptxåº“æœªå®‰è£…ï¼Œæ— æ³•ç”ŸæˆPPTæ–‡ä»¶")
        
        # åˆ›å»ºæ¼”ç¤ºæ–‡ç¨¿
        if template_path:
            self.presentation = Presentation(template_path)
        else:
            self.presentation = Presentation()
            
        # è§£æå¤§çº²
        slides_data = self._parse_outline(outline_data)
        
        # ç”Ÿæˆå¹»ç¯ç‰‡
        for slide_data in slides_data:
            self._create_slide(slide_data)
        
        # ä¿å­˜åˆ°BytesIO
        ppt_buffer = BytesIO()
        self.presentation.save(ppt_buffer)
        ppt_buffer.seek(0)
        
        return ppt_buffer
    
    def _parse_outline(self, outline_text: str) -> List[Dict]:
        """è§£æå¤§çº²æ–‡æœ¬"""
        slides = []
        current_slide = {}
        
        lines = outline_text.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            if line == '---':
                if current_slide:
                    slides.append(current_slide)
                    current_slide = {}
                continue
            
            if line.startswith('**Slide:**'):
                current_slide['slide_num'] = line.split('**Slide:**')[1].strip()
            elif line.startswith('**Title:**'):
                current_slide['title'] = line.split('**Title:**')[1].strip()
            elif line.startswith('**Purpose:**'):
                current_slide['purpose'] = line.split('**Purpose:**')[1].strip()
            elif line.startswith('**Content:**'):
                current_slide['content'] = []
            elif line.startswith('- ') and 'content' in current_slide:
                current_slide['content'].append(line[2:].strip())
            elif line.startswith('**Visual:**'):
                current_slide['visual'] = {}
            elif line.startswith('  - **Type:**') and 'visual' in current_slide:
                current_slide['visual']['type'] = line.split('**Type:**')[1].strip()
        
        if current_slide:
            slides.append(current_slide)
            
        return slides
    
    def _create_slide(self, slide_data: Dict):
        """åˆ›å»ºå•ä¸ªå¹»ç¯ç‰‡"""
        # æ ¹æ®purposeé€‰æ‹©å¸ƒå±€
        purpose = slide_data.get('purpose', 'Content')
        
        if purpose == 'Title':
            layout = self.presentation.slide_layouts[0]  # æ ‡é¢˜å¸ƒå±€
        else:
            layout = self.presentation.slide_layouts[1]  # å†…å®¹å¸ƒå±€
            
        slide = self.presentation.slides.add_slide(layout)
        
        # è®¾ç½®æ ‡é¢˜
        if slide.shapes.title:
            slide.shapes.title.text = slide_data.get('title', '')
        
        # è®¾ç½®å†…å®¹
        content = slide_data.get('content', [])
        if content and len(slide.placeholders) > 1:
            body_shape = slide.placeholders[1]
            tf = body_shape.text_frame
            tf.clear()
            
            for i, item in enumerate(content):
                if i == 0:
                    tf.text = item
                else:
                    p = tf.add_paragraph()
                    p.text = item
                    p.level = 0

# --- æ ¸å¿ƒå¤„ç†å‡½æ•° ---
def parse_pdf(uploaded_file, debug_log_container):
    """è§£æPDFæ–‡ä»¶"""
    try:
        file_bytes = uploaded_file.getvalue()
        doc = fitz.open(stream=file_bytes, filetype="pdf")
        full_text = "".join(page.get_text() + "\n" for page in doc)
        debug_log_container.write(f"âœ… PDFè§£ææˆåŠŸã€‚æ€»è®¡ {len(full_text):,} ä¸ªå­—ç¬¦ã€‚")
        return full_text
    except Exception:
        debug_log_container.error(f"PDFè§£ææ—¶å‡ºç°å¼‚å¸¸: {traceback.format_exc()}")
        return None

def call_ai_api(provider_name: str, model: str, api_key: str, prompt: str, stream_callback=None, debug_log_container=None) -> Optional[str]:
    """ç»Ÿä¸€AI APIè°ƒç”¨æ¥å£"""
    if provider_name not in PROVIDERS:
        if debug_log_container:
            debug_log_container.error(f"ä¸æ”¯æŒçš„AIå‚å•†: {provider_name}")
        return None
    
    provider = PROVIDERS[provider_name]
    
    if debug_log_container:
        debug_log_container.write(f"æ­£åœ¨è°ƒç”¨ {provider_name} - {model}...")
        debug_log_container.write(f"Prompté•¿åº¦: {len(prompt):,} å­—ç¬¦")
    
    try:
        result = provider.call_api(prompt, model, api_key, stream_callback)
        if debug_log_container:
            debug_log_container.write(f"âœ… {provider_name} APIè°ƒç”¨æˆåŠŸ")
        return result
    except Exception as e:
        if debug_log_container:
            debug_log_container.error(f"âŒ {provider_name} APIè°ƒç”¨å¤±è´¥: {e}")
        return None

def extract_clean_outline(raw_output, debug_log_container):
    """æå–æ¸…æ´çš„å¤§çº²"""
    try:
        match = re.search(r"\*\*\s*Slide\s*:\s*\*\*", raw_output)
        if not match:
            debug_log_container.error("âŒ åœ¨AIå“åº”ä¸­æœªèƒ½æ‰¾åˆ°ä»»ä½•`**Slide:**`æ ‡è®°ã€‚")
            return None
        first_slide_pos = match.start()
        last_divider_pos = raw_output.rfind("---", 0, first_slide_pos)
        cleaned_outline = raw_output[last_divider_pos:] if last_divider_pos != -1 else raw_output[first_slide_pos:]
        cleaned_outline = cleaned_outline.strip()
        if cleaned_outline.count("**Title:**") < 3:
            debug_log_container.warning("âš ï¸ æå–å‡ºçš„å¤§çº²ç»“æ„ä¸å®Œæ•´ã€‚")
        debug_log_container.success(f"âœ… å·²æ™ºèƒ½è¯†åˆ«å¹¶æå–å‡ºå¤§çº²å†…å®¹ã€‚")
        return cleaned_outline
    except Exception:
        debug_log_container.error(f"æå–å¤§çº²æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {traceback.format_exc()}")
        return None

def final_cleanup(raw_html, debug_log_container):
    """æœ€ç»ˆHTMLæ¸…ç†"""
    try:
        debug_log_container.write(f"å¼€å§‹æ¸…ç†HTMLï¼ŒåŸå§‹é•¿åº¦: {len(raw_html):,} å­—ç¬¦")
        
        html_start_pos = raw_html.find("<!DOCTYPE html>")
        if html_start_pos == -1:
            debug_log_container.warning("âš ï¸ æœªæ‰¾åˆ°`<!DOCTYPE html>`ï¼Œå°è¯•å¯»æ‰¾`<html`æ ‡ç­¾")
            html_start_pos = raw_html.find("<html")
            if html_start_pos == -1:
                debug_log_container.error("âŒ æœªæ‰¾åˆ°HTMLèµ·å§‹æ ‡ç­¾")
                return None
        
        html_end_pos = raw_html.rfind("</html>")
        if html_end_pos == -1:
            debug_log_container.error("âŒ æœªæ‰¾åˆ°HTMLç»“æŸæ ‡ç­¾")
            return None
        
        html_content = raw_html[html_start_pos:html_end_pos + 7]
        html_content = html_content.strip()
        
        if not (html_content.startswith("<!DOCTYPE html>") or html_content.startswith("<html")):
            debug_log_container.error("âŒ æ¸…ç†åçš„HTMLæ ¼å¼ä¸æ­£ç¡®")
            return None
            
        if not html_content.endswith("</html>"):
            debug_log_container.error("âŒ æ¸…ç†åçš„HTMLç»“å°¾ä¸æ­£ç¡®")
            return None
        
        debug_log_container.success(f"âœ… HTMLæ¸…ç†å®Œæˆï¼æœ€ç»ˆé•¿åº¦: {len(html_content):,} å­—ç¬¦")
        return html_content
        
    except Exception as e:
        debug_log_container.error(f"æœ€ç»ˆæ¸…ç†æ—¶å‡ºé”™: {traceback.format_exc()}")
        return None

# --- Streamlit UI ---
st.set_page_config(page_title="ä¸‰å¤§å‚å•†AIå­¦æœ¯æ±‡æŠ¥ç”Ÿæˆå™¨", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ ä¸‰å¤§å‚å•†AIå­¦æœ¯æ±‡æŠ¥ç”Ÿæˆå™¨ (ç²¾ç®€ç‰ˆ)")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ AIå‚å•†é…ç½®")
    
    # é€‰æ‹©AIå‚å•†
    available_providers = list(PROVIDERS.keys())
    selected_provider = st.selectbox("é€‰æ‹©AIå‚å•†", available_providers, index=0)
    
    # è·å–è¯¥å‚å•†çš„å¯ç”¨æ¨¡å‹
    models = PROVIDERS[selected_provider].get_models()
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", models, index=0)
    
    # API Keyè¾“å…¥
    api_key_mapping = {
        "OpenAI": DEFAULT_CONFIG.openai_key,
        "Gemini": DEFAULT_CONFIG.gemini_key,
        "Claude": DEFAULT_CONFIG.anthropic_key
    }
    
    default_key = api_key_mapping.get(selected_provider, "")
    api_key = st.text_input(
        f"è¯·è¾“å…¥{selected_provider} API Key", 
        value=default_key,
        type="password",
        help="ğŸ’¡ å¯ä»¥åœ¨ä»£ç ä¸­é¢„è®¾é»˜è®¤API Key"
    )
    
    # éªŒè¯API Key
    if api_key:
        if PROVIDERS[selected_provider].validate_key(api_key):
            st.success(f"âœ… {selected_provider} API KeyéªŒè¯é€šè¿‡")
        else:
            st.error(f"âŒ {selected_provider} API KeyéªŒè¯å¤±è´¥")
    
    st.divider()
    st.header("ğŸ“„ è¾“å‡ºæ ¼å¼")
    
    # è¾“å‡ºæ ¼å¼é€‰æ‹©
    output_formats = st.multiselect(
        "é€‰æ‹©è¾“å‡ºæ ¼å¼",
        ["HTMLæ¼”ç¤ºæ–‡ç¨¿", "PPTæ–‡ä»¶"],
        default=["HTMLæ¼”ç¤ºæ–‡ç¨¿"]
    )

# ä¸»ç•Œé¢
col1, col2 = st.columns(2)
with col1:
    pdf_file = st.file_uploader("1. ä¸Šä¼ æ‚¨çš„å­¦æœ¯è®ºæ–‡ (.pdf)", type=['pdf'])
with col2:
    html_template = st.file_uploader("2. ä¸Šä¼ æ‚¨çš„HTMLæ¨¡æ¿ (å¯é€‰)", type=['html'])

# å­˜å‚¨ç”Ÿæˆçš„ç»“æœ
if 'results' not in st.session_state:
    st.session_state.results = {}

# ç”ŸæˆæŒ‰é’®
if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆæ±‡æŠ¥", use_container_width=True, 
             disabled=(not api_key or not pdf_file or not output_formats)):
    
    st.session_state.results = {}
    
    progress_container = st.container()
    progress_text = progress_container.empty()
    progress_bar = progress_container.progress(0)
    
    with st.expander("ğŸ **è°ƒè¯•æ—¥å¿—**", expanded=False):
        debug_log_container = st.container()
    
    # è§£æPDF
    paper_text = parse_pdf(pdf_file, debug_log_container)
    if not paper_text:
        st.error("PDFè§£æå¤±è´¥")
        st.stop()
    
    progress_bar.progress(10)
    
    # ç”Ÿæˆå¤§çº²
    progress_text.text("æ­¥éª¤ 1/3: æ­£åœ¨ç”Ÿæˆæ¼”ç¤ºæ–‡ç¨¿å¤§çº²...")
    prompt_for_outline = OUTLINE_GENERATION_PROMPT_TEMPLATE + "\n\n--- å­¦æœ¯æ–‡æ¡£å…¨æ–‡ ---\n" + paper_text
    
    outline_placeholder = st.empty()
    
    def stream_callback(text):
        # å¯ä»¥åœ¨è¿™é‡Œå¤„ç†æµå¼è¾“å‡º
        pass
    
    markdown_outline = call_ai_api(
        selected_provider, 
        selected_model, 
        api_key, 
        prompt_for_outline, 
        stream_callback, 
        debug_log_container
    )
    
    if not markdown_outline:
        st.error("å¤§çº²ç”Ÿæˆå¤±è´¥")
        st.stop()
    
    progress_bar.progress(40)
    outline_placeholder.empty()
    
    # æ¸…ç†å¤§çº²
    progress_text.text("æ­¥éª¤ 2/3: æ­£åœ¨å¤„ç†å¤§çº²...")
    cleaned_outline = extract_clean_outline(markdown_outline, debug_log_container)
    
    if not cleaned_outline:
        st.error("å¤§çº²å¤„ç†å¤±è´¥")
        st.stop()
    
    progress_bar.progress(50)
    
    # ç”ŸæˆHTML
    if "HTMLæ¼”ç¤ºæ–‡ç¨¿" in output_formats:
        if not html_template:
            st.error("ç”ŸæˆHTMLéœ€è¦ä¸Šä¼ HTMLæ¨¡æ¿")
        else:
            progress_text.text("æ­¥éª¤ 3a/3: æ­£åœ¨ç”ŸæˆHTMLæ¼”ç¤ºæ–‡ç¨¿...")
            
            template_code = html_template.getvalue().decode("utf-8")
            
            final_prompt = "".join([
                CODE_GENERATION_PROMPT_TEMPLATE,
                "\n\n--- PPT Outline ---\n",
                cleaned_outline,
                "\n\n--- HTML Template ---\n",
                template_code
            ])
            
            with st.spinner("æ­£åœ¨ç”ŸæˆHTML..."):
                final_html_raw = call_ai_api(
                    selected_provider,
                    selected_model,
                    api_key,
                    final_prompt,
                    None,
                    debug_log_container
                )
            
            if final_html_raw:
                final_html_code = final_cleanup(final_html_raw, debug_log_container)
                if final_html_code:
                    st.session_state.results['html'] = final_html_code
                    debug_log_container.success("âœ… HTMLç”ŸæˆæˆåŠŸï¼")
                else:
                    st.error("HTMLæ¸…ç†å¤±è´¥")
            else:
                st.error("HTMLç”Ÿæˆå¤±è´¥")
    
    progress_bar.progress(70)
    
    # ç”ŸæˆPPT
    if "PPTæ–‡ä»¶" in output_formats:
        if not PPTX_AVAILABLE:
            st.error("PPTç”Ÿæˆéœ€è¦å®‰è£…python-pptxåº“: pip install python-pptx")
        else:
            progress_text.text("æ­¥éª¤ 3b/3: æ­£åœ¨ç”ŸæˆPPTæ–‡ä»¶...")
            
            try:
                ppt_generator = PPTGenerator()
                ppt_buffer = ppt_generator.create_presentation(cleaned_outline)
                st.session_state.results['ppt'] = ppt_buffer.getvalue()
                debug_log_container.success("âœ… PPTç”ŸæˆæˆåŠŸï¼")
            except Exception as e:
                st.error(f"PPTç”Ÿæˆå¤±è´¥: {e}")
                debug_log_container.error(f"PPTç”Ÿæˆé”™è¯¯: {traceback.format_exc()}")
    
    progress_bar.progress(100)
    progress_text.text("ğŸ‰ ç”Ÿæˆå®Œæˆï¼")

# ä¸‹è½½åŒºåŸŸ
if st.session_state.results:
    st.header("ğŸ“¥ ä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if 'html' in st.session_state.results:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½HTMLæ¼”ç¤ºæ–‡ç¨¿",
                data=st.session_state.results['html'].encode('utf-8'),
                file_name='presentation.html',
                mime='text/html',
                use_container_width=True
            )
    
    with col2:
        if 'ppt' in st.session_state.results:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½PPTæ–‡ä»¶",
                data=st.session_state.results['ppt'],
                file_name='presentation.pptx',
                mime='application/vnd.openxmlformats-officedocument.presentationml.presentation',
                use_container_width=True
            )

# ä¾èµ–è¯´æ˜
st.sidebar.divider()
st.sidebar.header("ğŸ“¦ ä¾èµ–åº“çŠ¶æ€")
st.sidebar.write("âœ… PyMuPDF")
st.sidebar.write("âœ… python-pptx" if PPTX_AVAILABLE else "âŒ python-pptx")
st.sidebar.write("âœ… google-generativeai" if GEMINI_AVAILABLE else "âŒ google-generativeai")
st.sidebar.write("âœ… openai" if OPENAI_AVAILABLE else "âŒ openai")
st.sidebar.write("âœ… anthropic" if ANTHROPIC_AVAILABLE else "âŒ anthropic")

if not PPTX_AVAILABLE:
    st.sidebar.info("ğŸ’¡ å®‰è£…python-pptxä»¥å¯ç”¨PPTç”ŸæˆåŠŸèƒ½")